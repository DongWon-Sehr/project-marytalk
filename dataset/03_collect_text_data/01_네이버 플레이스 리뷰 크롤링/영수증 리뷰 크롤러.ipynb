{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"영수증 리뷰 크롤러.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"D4b26QCtQUQe","colab_type":"code","colab":{}},"source":["from bs4 import BeautifulSoup\n","import requests\n","import urllib.request\n","import pandas as pd\n","import numpy as np\n","from pandas import Series, DataFrame\n","from tqdm import tqdm, tqdm_notebook\n","import time\n","import os\n","from datetime import datetime\n","import random\n","from threading import Thread"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yDMwOpkqQUQh","colab_type":"code","colab":{}},"source":["#naver_map_seoul_salon_output_data_2020-04-19_final.csv 파일 경로\n","path = './naver_place_count_total_2020-05-01_final.csv'\n","#이미지 파일 저장할 디렉토리 설정. 반드시 끝에 /를 포함하셔야 합니다.\n","# imgDir = 'd:/marytalk/image/reviews/'\n","#크롤링할 업소 인덱스 번호 설정\n","#자신의 크롬 버젼에 따라서 Chrome/80.0.3987.163 부분을 수정해주세요\n","headers = {\"User-Agent\" : \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n","            AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36\", \n","            \"Accept\":\"text/html,application/xhtml+xml,application/xml;\\\n","            q=0.9,imgwebp,*/*;q=0.8\"}\n","\n","#업소 CSV파일 불러오기\n","salonDF = pd.read_csv(path)\n","salonDF = salonDF[['store_id_only_num', 'store_name']]\n","\n","#영수증 리뷰 함수            \n","def receipt_crawler(start, end):\n","    review_list = []\n","    rejected_salon_list = []\n","    empty_list = []\n","    baseurl = 'https://store.naver.com/hairshops/detail?id='\n","    for code_index in tqdm_notebook(range(start, end)):\n","        page_number=0\n","        time.sleep(random.uniform(2,8)+np.random.rand())\n","        while 1 :\n","            receipt_url = baseurl + str(salonDF.store_id_only_num[code_index])+'&tab=receiptReview&tabPage='+str(page_number)\n","            print(receipt_url)\n","            html = requests.get(receipt_url, headers=headers)\n","            time.sleep(6+np.random.rand())\n","            naver_place = BeautifulSoup(html.text, 'html.parser')\n","\n","            \n","            if html.status_code != 200 :\n","                reject_salon = {\"store_id_only_num\":salonDF.store_id_only_num[code_index] ,\"store_name\":salonDF.store_name[code_index]}\n","                rejected_salon_list.append(reject_salon)\n","                print(str(code_index) + \" \"+salonDF.store_name[code_index]+\" 리뷰 데이터 불러오기 실패\")\n","                break\n","                                \n","            elif naver_place.find('ul', class_=\"list_receipt_review\") is None :\n","                empty_salon = {\"store_id_only_num\":salonDF.store_id_only_num[code_index] ,\"store_name\":salonDF.store_name[code_index]}\n","                empty_list.append(empty_salon)\n","                print(str(code_index) + \" \"+salonDF.store_name[code_index]+\" 리뷰 데이터 없음\")\n","                break\n","            \n","                \n","            else : \n","                try :\n","                    lastpage = naver_place.find('span', class_='total').get_text()\n","                except AttributeError :\n","                    lastpage = 1\n","                reviews = naver_place.find('ul', class_=\"list_receipt_review\").find_all('li', class_=[\"list_item\",\"list_item no_img\"])\n","                for rev in tqdm(reviews) :\n","                    #하나의 리뷰에서 별점 가져오기 \n","                    score = rev.find('span', class_='score').get_text()\n","\n","                    #하나의 리뷰에서 리뷰 가져오기\n","                    review = rev.find('div', class_='review_txt').get_text()\n","\n","                    #하나의 리뷰에서 작성자 가져오기\n","                    reviewer_nickname = rev.find('a', class_='item').get_text()\n","\n","                    #하나의 리뷰에서 작성일자 가져오기\n","                    write_date = rev.find_all('span', class_='item')[0].get_text()\n","                    write_date = datetime.strptime(write_date,'%Y.%m.%d').strftime('%Y%m%d')\n","                    \n","                    #하나의 리뷰에서 방문 빈도수 가져오기\n","                    frequency = rev.find_all('span', class_='item')[1].get_text().rstrip('번째 방문')\n","\n","                    #pk\n","                    #pk = salonDF.store_id_only_num[code_index]+'R'+str(write_date)+reviewer_nickname+str(frequency)\n","                    #pk = \"\".join(i for i in pk if i not in \"\\/:*?<>|\")\n","                    rev_info = {'store_id_only_num':salonDF.store_id_only_num[code_index],'store_name': salonDF.store_name[code_index],'score':score, 'review':review, \n","                                'reviewer_nickname':reviewer_nickname, 'write_date':write_date, 'frequency':frequency}\n","                    review_list.append(rev_info)\n","                    print(str(code_index) + \" \"+salonDF.store_name[code_index] + \" 리뷰 저장.\")\n","\n","                print(str(code_index) + \" \"+salonDF.store_name[code_index] + \" \" + str(page_number+1) + \"/\"+ str(lastpage) + \" 페이지 완료\")\n","                if str(page_number+1)==str(lastpage) :\n","                    print(str(code_index) + \" \"+salonDF.store_name[code_index] + \" 리뷰 저장 완료\")\n","                    html.close()\n","                    break\n","                else :\n","                    page_number+=1\n","                    time.sleep(5)\n","                    \n","    receipt_reviewDF=DataFrame(review_list)\n","    receipt_reviewDF.to_csv(\"naver_place_receipt_review(%i-%i).csv\" %(start, end-1), sep=',', encoding='utf-8-sig')\n","    reject_receipt_salon= DataFrame(rejected_salon_list)\n","    reject_receipt_salon.to_csv(\"naver_reject_receipt_salon(%i-%i).csv\" %(start, end-1), sep=',', encoding='utf-8-sig')\n","    empty_receipt_reviewDF=DataFrame(empty_list)\n","    empty_receipt_reviewDF.to_csv(\"naver_empty_receipt_review(%i-%i).csv\" %(start, end-1), sep=',', encoding='utf-8-sig')\n","\n","\n","def threading_craw(start, end, n_thread) :\n","    step = np.linspace(start, end, n_thread+1, dtype=int)\n","    ths = []\n","    \n","    for i in tqdm_notebook(range(0,n_thread)) :\n","        th = Thread(target=receipt_crawler, args=(step[i], step[i+1]))\n","        ths.append(th)\n","        th.start()\n","    \n","    for th in ths :\n","        th.join()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KJNptaw-QUQj","colab_type":"code","colab":{}},"source":["#0~2727\n","start=0\n","end=1000\n","n_thread = 15\n","\n","threading_craw(start, end, n_thread)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"84krj02ZQUQl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}